{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_R(units,layerz,metric,shape,lozz= 'logcosh'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(units, activation = 'relu', \n",
    "                           input_shape = (shape,)))\n",
    "    for layer in range(layerz):\n",
    "        model.add(layers.Dense(units, activation = 'relu'))\n",
    "    model.add(layers.Dense(1)) #linear layer\n",
    "    model.compile(optimizer = 'rmsprop', loss = lozz, metrics =[metric] )\n",
    "    return model\n",
    "\n",
    "def build_model_C(units,layerz,metric,shape,lozz = 'binary_crossentropy'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(units, activation = 'relu', \n",
    "                           kernel_regularizer = regularizers.l2(0.001),\n",
    "                           input_shape = (shape,)))\n",
    "    for layer in range(layerz):\n",
    "        model.add(layers.Dropout(0.4))\n",
    "        model.add(layers.Dense(units, activation = 'relu'))\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\")) \n",
    "    model.compile(optimizer = 'Adam', loss = lozz, metrics =[metric] )\n",
    "    return model\n",
    "\n",
    "def preprocess(path):    \n",
    "    pair_df = pd.read_csv(path)\n",
    "    pair_df.drop(columns = \"dateorder\", inplace = True)\n",
    "    data = pair_df.loc[:,'inter1_x':'fif12'].values.astype(\"float\")\n",
    "    labels = pair_df.loc[:,\"liked\":].values.astype(\"float\")\n",
    "    \n",
    "    # remove a column\n",
    "    \n",
    "    # randomize data and label set\n",
    "    sample_size = data.shape[0]\n",
    "    arr = np.arange(sample_size)\n",
    "    data = data[arr].reshape(data.shape)\n",
    "    labels = labels[arr].reshape(labels.shape)\n",
    "    \n",
    "    dependent_measures = dict(\n",
    "    liked = labels[:,0], sexatt = labels[:,1], likyes = labels[:,2],\n",
    "    fliked = labels[:,3], fsexatt = labels[:,4] , flikyes = labels[:,5],\n",
    "    saidyes = labels[:,6], fsaidyes = labels[:,6], match = labels[:,7]\n",
    "    )\n",
    "\n",
    "    # normalize\n",
    "    mean = data.mean(axis = 0)\n",
    "    std = data.std(axis = 0)\n",
    "\n",
    "    data -= mean\n",
    "    data /= std\n",
    "    \n",
    "    return data, dependent_measures,mean,std\n",
    "\n",
    "\n",
    "path = \"./pair2Dataframe.csv\"\n",
    "data, dependent_measures,mean,std  = preprocess(path)\n",
    "\n",
    "def save_model( measure, model , X = data ,units = 64, layerz = 5, num_epochs = 10):#\n",
    "\n",
    "    y = dependent_measures[measure]\n",
    "    shape = X.shape[1]\n",
    "    #Hyperparameters                                \n",
    "\n",
    "    # create model\n",
    "    build = dict( regression = build_model_R(units,layerz,'mae',shape),\n",
    "                  classification = build_model_C(units,layerz,\"accuracy\",shape)\n",
    "    )\n",
    "    model = build[model]\n",
    "    # train model\n",
    "    model.fit(X, y, epochs = num_epochs, batch_size = 500, verbose = 0 )\n",
    "    # Saving model\n",
    "    file = measure+'Model.h5'\n",
    "    print(file)\n",
    "    model.save(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saidyesModel.h5\n",
      "fsaidyesModel.h5\n",
      "matchModel.h5\n"
     ]
    }
   ],
   "source": [
    "save_model(\"saidyes\",\"classification\")\n",
    "save_model(\"fsaidyes\",\"classification\")\n",
    "save_model(\"match\",\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cardosoo/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/cardosoo/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/cardosoo/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "flikedModel.h5\n"
     ]
    }
   ],
   "source": [
    "#save_model(\"liked\",\"regression\")\n",
    "#save_model(\"sexatt\",\"regression\")\n",
    "#save_model(\"likyes\",\"regression\")\n",
    "save_model(\"fliked\",\"regression\")\n",
    "#save_model(\"fsexatt\",\"regression\")\n",
    "#save_model(\"flikyes\",\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict(mean= mean, std= std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"meanAndstd\",\"wb\")\n",
    "pickle.dump(hyperparameters,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
